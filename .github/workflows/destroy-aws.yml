name: Destroy AWS Infrastructure

on:
  workflow_dispatch:

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
  AWS_DEFAULT_REGION: ${{ secrets.TF_REGION }}
  TF_VAR_region: ${{ secrets.TF_REGION }}
  TF_VAR_eks_cluster_name: ${{ secrets.TF_EKS_CLUSTER_NAME }}
  TF_VAR_ecr_name: ${{ secrets.TF_ECR_NAME }}

jobs:
  destroy:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.8.3"

      - name: Terraform Init
        id: init
        working-directory: aws-terraform/
        run: terraform init

      - name: Export Terraform Outputs
        id: tf-outputs
        working-directory: aws-terraform/
        run: |
          echo "EKS_CLUSTER_NAME=$(terraform output -raw eks_cluster_name || echo '')" >> $GITHUB_ENV
          echo "REGION=$(terraform output -raw region || echo '${{ secrets.TF_REGION }}')" >> $GITHUB_ENV

      - name: Check if EKS Cluster Exists
        id: check_cluster
        run: |
          if [ -z "$EKS_CLUSTER_NAME" ]; then
            echo "exists=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if aws eks describe-cluster --name $EKS_CLUSTER_NAME --region $REGION >/dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Graceful Kubernetes Cleanup
        if: steps.check_cluster.outputs.exists == 'true'
        run: |
          aws eks update-kubeconfig --region $REGION --name $EKS_CLUSTER_NAME
          
          helm uninstall eck-stack-with-logstash -n elastic-stack || true
          helm uninstall elastic-operator -n elastic-system || true
          helm uninstall ingress-nginx -n ingress-nginx || true
          helm uninstall cert-manager -n cert-manager || true
          helm uninstall kube-prometheus-stack -n monitoring || true
          helm uninstall cluster-autoscaler -n kube-system || true
          
          kubectl delete ingress --all --all-namespaces
          kubectl wait --for=delete ingress --all --all-namespaces --timeout=5m || true

          kubectl get services --all-namespaces -o json | \
          jq -r '.items[] | select(.spec.type=="LoadBalancer") | .metadata.namespace + " " + .metadata.name' | \
          while read -r namespace name; do
            if [ -n "$namespace" ] && [ -n "$name" ]; then
              kubectl delete service "$name" -n "$namespace"
            fi
          done
          
          sleep 300

      - name: Terraform Destroy
        id: destroy
        working-directory: aws-terraform/
        run: terraform destroy -auto-approve