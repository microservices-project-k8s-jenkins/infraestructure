name: Deploy Infrastructure to AWS

on:
  workflow_dispatch:

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION: ${{ secrets.TF_REGION }}
  AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
  TF_VAR_region:                ${{ secrets.TF_REGION }}
  TF_VAR_eks_cluster_name:     ${{ secrets.TF_EKS_CLUSTER_NAME }}
  TF_VAR_ecr_name:             ${{ secrets.TF_ECR_NAME }}

jobs:
  deploy_infra:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.8.3"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: aws-terraform/
        run: terraform init

      - name: Terraform Validate
        working-directory: aws-terraform/
        run: terraform validate

      - name: Terraform Plan
        working-directory: aws-terraform/
        run: terraform plan -no-color

      - name: Terraform Apply
        working-directory: aws-terraform/
        run: terraform apply -auto-approve -no-color

      - name: Export Terraform Outputs
        working-directory: aws-terraform/
        run: |
          echo "ECR_REPOSITORY_URL=$(terraform output -raw ecr_repository_url)" > tf_outputs.env
          echo "SECRETS_MANAGER_NAME=$(terraform output -raw secrets_manager_name)" >> tf_outputs.env
          echo "EKS_CLUSTER_NAME=$(terraform output -raw eks_cluster_name)" >> tf_outputs.env
          echo "REGION=$(terraform output -raw region)" >> tf_outputs.env
          # Si implementaste IRSA para Cluster Autoscaler, también exportarías ese ARN aquí
          # echo "CLUSTER_AUTOSCALER_IAM_ROLE_ARN=$(terraform output -raw cluster_autoscaler_iam_role_arn)" >> tf_outputs.env

      - name: Upload Terraform Outputs Artifact
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: aws-terraform/tf_outputs.env
          retention-days: 1
          overwrite: true

  bootstrap_argocd: # Renombrar a algo como bootstrap_cluster_tools si ArgoCD es solo una parte
    needs: deploy_infra
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Terraform Outputs
        uses: actions/download-artifact@v4
        with:
          name: terraform-outputs
          path: .

      - name: Load Terraform Outputs into Env Vars
        run: |
          cat tf_outputs.env
          source tf_outputs.env
          echo "EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME}" >> $GITHUB_ENV
          echo "REGION=${REGION}" >> $GITHUB_ENV

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --region ${{ env.REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'

      - name: Add Helm Repos
        run: |
          helm repo add autoscaler https://kubernetes.github.io/autoscaler
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update

      - name: Install Cluster Autoscaler
        run: |
          helm upgrade --install cluster-autoscaler autoscaler/cluster-autoscaler \
            --namespace kube-system \
            --set autoDiscovery.clusterName=${{ env.EKS_CLUSTER_NAME }} \
            --set awsRegion=${{ env.REGION }} \
            --set rbac.create=true \
            --set rbac.serviceAccount.create=true \
            --set rbac.serviceAccount.name=cluster-autoscaler
            # Si usas IRSA, añade:
            # --set rbac.serviceAccount.annotations."eks\.amazonaws\.com/role-arn"="${{ env.CLUSTER_AUTOSCALER_IAM_ROLE_ARN }}"

      - name: Install Prometheus and Grafana (kube-prometheus-stack)
        run: |
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --set grafana.adminPassword='Password@1234' \
            --set grafana.service.type=ClusterIP \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage="" \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.storageClassName="" \
            --set prometheus.prometheusSpec.persistentVolume.enabled=false \
            --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage="" \
            --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.storageClassName="" \
            --set alertmanager.alertmanagerSpec.persistentVolume.enabled=false \
            --set grafana.persistence.enabled=false

      - name: Clone Helm Charts Repository for ArgoCD
        run: |
          git clone https://github.com/microservices-project-k8s-jenkins/ecommerce-charts.git
          chmod +x ./ecommerce-charts/scripts/bootstrap.sh
          echo "Waiting for monitoring pods to be ready..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=kube-prometheus-stack -n monitoring --timeout=300s || echo "Timeout waiting for monitoring pods, continuing..."
          ./ecommerce-charts/scripts/bootstrap.sh