name: Deploy Infrastructure to AWS

on:
  workflow_dispatch:
    inputs:
      destroy:
        description: 'Destroy infrastructure'
        required: false
        default: false
        type: boolean

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION: ${{ secrets.TF_REGION }}
  AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
  TF_VAR_region: ${{ secrets.TF_REGION }}
  TF_VAR_eks_cluster_name: ${{ secrets.TF_EKS_CLUSTER_NAME }}

jobs:
  deploy_infra:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.9.8"
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: aws-terraform/
        run: terraform init

      - name: Terraform Validate
        working-directory: aws-terraform/
        run: terraform validate

      - name: Terraform Plan
        working-directory: aws-terraform/
        run: terraform plan -no-color -out=tfplan

      - name: Terraform Apply
        if: ${{ !inputs.destroy }}
        working-directory: aws-terraform/
        run: terraform apply -auto-approve -no-color tfplan

      - name: Terraform Destroy
        if: ${{ inputs.destroy }}
        working-directory: aws-terraform/
        run: terraform destroy -auto-approve -no-color

      - name: Export Terraform Outputs
        if: ${{ !inputs.destroy }}
        working-directory: aws-terraform/
        run: |
          echo "EKS_CLUSTER_NAME=$(terraform output -raw eks_cluster_name)" >> tf_outputs.env
          echo "REGION=$(terraform output -raw region)" >> tf_outputs.env

      - name: Upload Terraform Outputs Artifact
        if: ${{ !inputs.destroy }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: aws-terraform/tf_outputs.env
          retention-days: 1
          overwrite: true

  bootstrap_cluster:
    if: ${{ !inputs.destroy }}
    needs: deploy_infra
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Terraform Outputs
        uses: actions/download-artifact@v4
        with:
          name: terraform-outputs
          path: .

      - name: Load Terraform Outputs into Env Vars
        run: |
          cat tf_outputs.env
          source tf_outputs.env
          echo "EKS_CLUSTER_NAME=${EKS_CLUSTER_NAME}" >> $GITHUB_ENV
          echo "REGION=${REGION}" >> $GITHUB_ENV
          
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ env.REGION }}

      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --region ${{ env.REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Add Helm Repos
        run: |
          helm repo add autoscaler https://kubernetes.github.io/autoscaler
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo add jetstack https://charts.jetstack.io
          helm repo add elastic https://helm.elastic.co
          helm repo update

      - name: Wait for cluster to be ready
        run: |
          kubectl wait --for=condition=Ready nodes --all --timeout=300s

      - name: Install Linkerd CLI
        run: |
          curl -sL https://run.linkerd.io/install | sh
          export PATH=$PATH:$HOME/.linkerd2/bin
          echo "$HOME/.linkerd2/bin" >> $GITHUB_PATH

      - name: Check Cluster for Linkerd Compatibility
        run: |
          linkerd check --pre

      - name: Install Gateway API CRDs
        run: |
          kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.2.1/standard-install.yaml

      - name: Install Linkerd CRDs
        run: |
          linkerd install --crds | kubectl apply -f -

      - name: Install Linkerd Control Plane
        run: |
          linkerd install | kubectl apply -f -
          linkerd check

      - name: Install Linkerd Viz Extension (Dashboard)
        run: |
          linkerd viz install | kubectl apply -f -
          linkerd viz check

      - name: Install Metrics Server
        run: |
          helm upgrade --install metrics-server metrics-server/metrics-server \
            --namespace kube-system \
            --set args="{--kubelet-insecure-tls}" \
            --wait

      - name: Install NGINX Ingress Controller
        run: |
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.service.type=LoadBalancer \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"="nlb" \
            --wait

      - name: Install Cert Manager
        run: |
          helm upgrade --install cert-manager jetstack/cert-manager \
            --namespace cert-manager \
            --create-namespace \
            --version v1.16.1 \
            --set crds.enabled=true \
            --wait

      - name: Install Calico Network Policies
        run: |
          kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.2/manifests/calico-policy-only.yaml
          kubectl wait --for condition=Ready pods -l k8s-app=calico-kube-controllers -n kube-system --timeout=300s

      - name: Install ECK Operator
        run: |
          helm upgrade --install elastic-operator elastic/eck-operator \
            --namespace elastic-system \
            --create-namespace \
            --wait

      - name: Wait for ECK CRDs
        run: |
          kubectl wait --for condition=Established crd/elasticsearches.elasticsearch.k8s.elastic.co --timeout=120s
          kubectl wait --for condition=Established crd/kibanas.kibana.k8s.elastic.co --timeout=120s
          kubectl wait --for condition=Established crd/logstashes.logstash.k8s.elastic.co --timeout=120s
          kubectl wait --for condition=Established crd/beats.beat.k8s.elastic.co --timeout=120s

      - name: Install ECK Stack with Logstash
        run: |
          curl -sSfL -o basic-eck.yaml https://raw.githubusercontent.com/elastic/cloud-on-k8s/3.0/deploy/eck-stack/examples/logstash/basic-eck.yaml
          sed -i '/daemonSet: null/d' basic-eck.yaml
          sed -i 's/type: log/type: filestream/g' basic-eck.yaml
          
          helm upgrade --install eck-stack-with-logstash elastic/eck-stack \
            --values basic-eck.yaml \
            --namespace elastic-stack \
            --create-namespace \
            --wait \
            --timeout 10m

      - name: Install Prometheus and Grafana
        run: |
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --version 65.1.1 \
            --set grafana.adminPassword='${{ secrets.GRAFANA_PASSWORD || 'Password@1234' }}' \
            --set grafana.service.type=ClusterIP \
            --set prometheus.prometheusSpec.retention=30d \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=20Gi \
            --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage=5Gi \
            --set prometheus.prometheusSpec.ruleSelectorNilUsesHelmValues=false \
            --set prometheus.prometheusSpec.ruleSelector.matchLabels.release=kube-prometheus-stack \
            --wait \
            --timeout 10m

      - name: Create Alert Rules as PrometheusRule
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: monitoring.coreos.com/v1
          kind: PrometheusRule
          metadata:
            name: custom-alert-rules
            namespace: monitoring
            labels:
              release: kube-prometheus-stack
          spec:
            groups:
              - name: example.rules
                rules:
                  - alert: HighCPUUsage
                    expr: sum(rate(container_cpu_usage_seconds_total{image!=""}[1m])) by (pod) > 0.8
                    for: 1m
                    labels:
                      severity: warning
                    annotations:
                      summary: "High CPU usage detected on pod"
                      description: "Pod {{ \$labels.pod }} is using more than 80% CPU."
          EOF


      - name: Setup ArgoCD Bootstrap
        run: |
          echo "Cloning Helm Charts Repository..."
          git clone https://github.com/microservices-project-k8s-jenkins/ecommerce-charts.git
          
          if [ -f "./ecommerce-charts/scripts/bootstrap.sh" ]; then
            chmod +x ./ecommerce-charts/scripts/bootstrap.sh
            ./ecommerce-charts/scripts/bootstrap.sh
          else
            echo "Bootstrap script not found, skipping..."
          fi

      - name: Verify Installations
        run: |
          echo "=== Cluster Info ==="
          kubectl cluster-info
          
          echo "=== Node Status ==="
          kubectl get nodes -o wide
          
          echo "=== All Pods Status ==="
          kubectl get pods --all-namespaces
          
          echo "=== Services ==="
          kubectl get svc --all-namespaces
          
          echo "=== Ingress Controllers ==="
          kubectl get pods -n ingress-nginx
          
          echo "=== Load Balancer External IPs ==="
          kubectl get svc -n ingress-nginx
